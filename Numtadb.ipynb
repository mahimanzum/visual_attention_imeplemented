{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 72658,
     "status": "ok",
     "timestamp": 1566971082854,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD2lkgdC-M_53HbDklxXbBN0K9q5UMGVQMUi_3gQQ=s64",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "TIdUZhfZMyN_",
    "outputId": "b14b2564-182c-4690-fd67-ef574b1b3e06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Package 'python-software-properties' has no installation candidate\n",
      "Selecting previously unselected package google-drive-ocamlfuse.\n",
      "(Reading database ... 131183 files and directories currently installed.)\n",
      "Preparing to unpack .../google-drive-ocamlfuse_0.7.6-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
      "Unpacking google-drive-ocamlfuse (0.7.6-0ubuntu1~ubuntu18.04.1) ...\n",
      "Setting up google-drive-ocamlfuse (0.7.6-0ubuntu1~ubuntu18.04.1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
      "··········\n",
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
      "Please enter the verification code: Access token retrieved correctly.\n"
     ]
    }
   ],
   "source": [
    "#Block 1 server setup \n",
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HQAauXS3NHU3"
   },
   "outputs": [],
   "source": [
    "#Block 2 sync colabserver with drive\n",
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3FwaHt4MNZcW"
   },
   "outputs": [],
   "source": [
    "#ls drive/NumtaDB\n",
    "BASE = \"drive/NumtaDB/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10970,
     "status": "ok",
     "timestamp": 1566900573012,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD2lkgdC-M_53HbDklxXbBN0K9q5UMGVQMUi_3gQQ=s64",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "GyW1mWWANb-C",
    "outputId": "cec775d0-7e83-49a4-ef44-a07593fbab10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72045\n",
      "72045\n",
      "(72045, 64, 64, 3)\n",
      "(72045, 10)\n"
     ]
    }
   ],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "from keras.regularizers import l2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.math import add_n\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, GlobalAveragePooling2D\n",
    "from PIL import Image\n",
    "from keras import losses, optimizers, metrics\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import add, concatenate\n",
    "BASE = \"drive/NumtaDB/\"\n",
    "X_train = np.load(BASE+'x_train_all_64.npy')\n",
    "Y_train = np.load(BASE+'x_label_all_64.npy')\n",
    "#X_train = X_train[:len(X_train)//2]\n",
    "#Y_train = Y_train[:len(Y_train)//2]\n",
    "print(len(X_train))\n",
    "print(len(Y_train))\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3476522,
     "status": "ok",
     "timestamp": 1566913633088,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD2lkgdC-M_53HbDklxXbBN0K9q5UMGVQMUi_3gQQ=s64",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "a5IKKYc4Nsur",
    "outputId": "b25cd6a4-19de-47fe-a9fa-b22742c75df3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0827 12:49:31.542692 139750214027136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0827 12:49:31.580319 139750214027136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0827 12:49:31.590411 139750214027136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0827 12:49:31.642392 139750214027136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0827 12:49:31.643372 139750214027136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72045\n",
      "72045\n",
      "(72045, 64, 64, 3)\n",
      "(72045, 10)\n",
      "X_train original shape (72045, 64, 64, 3)\n",
      "y_train original shape (72045, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0827 12:49:35.153684 139750214027136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0827 12:49:35.564655 139750214027136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 8, 8, 192)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 16)   1216        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 16)   6416        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 16)   6416        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 32)   9248        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 32)   9248        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 32)   128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 64)   36928       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 64)   36928       batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 64)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 128)    73856       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 8, 128)    512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 128)    147584      batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 8, 128)    512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 192)    221376      batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 64, 192)      0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 (None, 64, 32)       117344      reshape_1[0][0]                  \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 8, 8, 32)     0           model_3[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_l_1 (NormL)                (None, 8, 8, 32)     64          reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           norm_l_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          524544      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           2570        dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,219,242\n",
      "Trainable params: 1,218,058\n",
      "Non-trainable params: 1,184\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0827 12:49:37.408972 139750214027136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0827 12:49:44.828289 139750214027136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "115/115 [==============================] - 78s 683ms/step - loss: 0.1858 - acc: 0.9651 - val_loss: 0.1416 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.97960, saving model to drive/NumtaDB/BEST_visual_atention_Callbacks_kfold5_v2.hdf5\n",
      "Epoch 2/10\n",
      "115/115 [==============================] - 68s 592ms/step - loss: 0.1664 - acc: 0.9712 - val_loss: 0.1260 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.97960 to 0.98307, saving model to drive/NumtaDB/BEST_visual_atention_Callbacks_kfold5_v2.hdf5\n",
      "Epoch 3/10\n",
      "115/115 [==============================] - 67s 585ms/step - loss: 0.1613 - acc: 0.9727 - val_loss: 0.2541 - val_acc: 0.9447\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.98307\n",
      "Epoch 4/10\n",
      "115/115 [==============================] - 67s 585ms/step - loss: 0.1597 - acc: 0.9734 - val_loss: 0.1167 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.98307 to 0.98681, saving model to drive/NumtaDB/BEST_visual_atention_Callbacks_kfold5_v2.hdf5\n",
      "Epoch 5/10\n",
      "115/115 [==============================] - 67s 586ms/step - loss: 0.1510 - acc: 0.9752 - val_loss: 0.1098 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.98681 to 0.98806, saving model to drive/NumtaDB/BEST_visual_atention_Callbacks_kfold5_v2.hdf5\n",
      "Epoch 6/10\n",
      "115/115 [==============================] - 68s 587ms/step - loss: 0.1437 - acc: 0.9762 - val_loss: 0.1052 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.98806 to 0.99042, saving model to drive/NumtaDB/BEST_visual_atention_Callbacks_kfold5_v2.hdf5\n",
      "Epoch 7/10\n",
      "115/115 [==============================] - 68s 588ms/step - loss: 0.1393 - acc: 0.9772 - val_loss: 0.1086 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99042\n",
      "Epoch 8/10\n",
      "115/115 [==============================] - 68s 587ms/step - loss: 0.1400 - acc: 0.9770 - val_loss: 0.1096 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99042\n",
      "Epoch 9/10\n",
      "115/115 [==============================] - 68s 587ms/step - loss: 0.1345 - acc: 0.9789 - val_loss: 0.1106 - val_acc: 0.9869\n",
      " \n",
      "Epoch 00008: reducing learning rate\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99042\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "new lr: 0.00050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 67s 587ms/step - loss: 0.1189 - acc: 0.9829 - val_loss: 0.0908 - val_acc: 0.9921\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.99042 to 0.99209, saving model to drive/NumtaDB/BEST_visual_atention_Callbacks_kfold5_v2.hdf5\n",
      "Epoch 1/10\n",
      "115/115 [==============================] - 68s 595ms/step - loss: 0.1140 - acc: 0.9838 - val_loss: 0.0706 - val_acc: 0.9974\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.99209 to 0.99736, saving model to drive/NumtaDB/BEST_visual_atention_Callbacks_kfold5_v2.hdf5\n",
      "Epoch 2/10\n",
      "115/115 [==============================] - 68s 588ms/step - loss: 0.1082 - acc: 0.9850 - val_loss: 0.0713 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.99736\n",
      "Epoch 3/10\n",
      "115/115 [==============================] - 67s 587ms/step - loss: 0.1041 - acc: 0.9859 - val_loss: 0.0722 - val_acc: 0.9963\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.99736\n",
      "Epoch 4/10\n",
      "115/115 [==============================] - 68s 587ms/step - loss: 0.1047 - acc: 0.9852 - val_loss: 0.0684 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.99736\n",
      "Epoch 5/10\n",
      "115/115 [==============================] - 67s 586ms/step - loss: 0.1041 - acc: 0.9860 - val_loss: 0.0720 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.99736\n",
      "Epoch 6/10\n",
      "115/115 [==============================] - 68s 588ms/step - loss: 0.1002 - acc: 0.9863 - val_loss: 0.0722 - val_acc: 0.9947\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.99736\n",
      "Epoch 7/10\n",
      "115/115 [==============================] - 68s 588ms/step - loss: 0.0990 - acc: 0.9862 - val_loss: 0.0708 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99736\n",
      "Epoch 8/10\n",
      "115/115 [==============================] - 67s 587ms/step - loss: 0.0981 - acc: 0.9859 - val_loss: 0.0661 - val_acc: 0.9963\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99736\n",
      "Epoch 9/10\n",
      "115/115 [==============================] - 68s 587ms/step - loss: 0.0960 - acc: 0.9863 - val_loss: 0.0673 - val_acc: 0.9949\n",
      " \n",
      "Epoch 00008: reducing learning rate\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99736\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "new lr: 0.00025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 67s 587ms/step - loss: 0.0883 - acc: 0.9883 - val_loss: 0.0630 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99736\n",
      "Epoch 1/10\n",
      "115/115 [==============================] - 68s 595ms/step - loss: 0.1069 - acc: 0.9860 - val_loss: 0.0673 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.99736 to 0.99806, saving model to drive/NumtaDB/BEST_visual_atention_Callbacks_kfold5_v2.hdf5\n",
      "Epoch 2/10\n",
      "115/115 [==============================] - 68s 588ms/step - loss: 0.1028 - acc: 0.9871 - val_loss: 0.0694 - val_acc: 0.9972\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.99806\n",
      "Epoch 3/10\n",
      "115/115 [==============================] - 68s 587ms/step - loss: 0.0983 - acc: 0.9877 - val_loss: 0.0668 - val_acc: 0.9973\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.99806\n",
      "Epoch 4/10\n",
      "115/115 [==============================] - 68s 587ms/step - loss: 0.0945 - acc: 0.9883 - val_loss: 0.0658 - val_acc: 0.9973\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.99806\n",
      "Epoch 5/10\n",
      "115/115 [==============================] - 68s 588ms/step - loss: 0.0948 - acc: 0.9885 - val_loss: 0.0638 - val_acc: 0.9975\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.99806\n",
      "Epoch 6/10\n",
      "115/115 [==============================] - 68s 587ms/step - loss: 0.0917 - acc: 0.9889 - val_loss: 0.0618 - val_acc: 0.9981\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.99806 to 0.99813, saving model to drive/NumtaDB/BEST_visual_atention_Callbacks_kfold5_v2.hdf5\n",
      "Epoch 7/10\n",
      "115/115 [==============================] - 68s 588ms/step - loss: 0.0897 - acc: 0.9892 - val_loss: 0.0634 - val_acc: 0.9972\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99813\n",
      "Epoch 8/10\n",
      "115/115 [==============================] - 68s 589ms/step - loss: 0.0897 - acc: 0.9889 - val_loss: 0.0621 - val_acc: 0.9972\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99813\n",
      "Epoch 9/10\n",
      "115/115 [==============================] - 68s 589ms/step - loss: 0.0874 - acc: 0.9889 - val_loss: 0.0621 - val_acc: 0.9966\n",
      " \n",
      "Epoch 00008: reducing learning rate\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99813\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "new lr: 0.00013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 68s 587ms/step - loss: 0.0873 - acc: 0.9891 - val_loss: 0.0597 - val_acc: 0.9976\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99813\n",
      "Epoch 1/10\n",
      "115/115 [==============================] - 68s 595ms/step - loss: 0.0886 - acc: 0.9894 - val_loss: 0.0575 - val_acc: 0.9989\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.99813 to 0.99889, saving model to drive/NumtaDB/BEST_visual_atention_Callbacks_kfold5_v2.hdf5\n",
      "Epoch 2/10\n",
      "115/115 [==============================] - 68s 588ms/step - loss: 0.0886 - acc: 0.9893 - val_loss: 0.0576 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.99889 to 0.99924, saving model to drive/NumtaDB/BEST_visual_atention_Callbacks_kfold5_v2.hdf5\n",
      "Epoch 3/10\n",
      "115/115 [==============================] - 68s 589ms/step - loss: 0.0860 - acc: 0.9898 - val_loss: 0.0568 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.99924\n",
      "Epoch 4/10\n",
      "115/115 [==============================] - 68s 588ms/step - loss: 0.0822 - acc: 0.9903 - val_loss: 0.0562 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.99924\n",
      "Epoch 5/10\n",
      "115/115 [==============================] - 68s 589ms/step - loss: 0.0811 - acc: 0.9905 - val_loss: 0.0551 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.99924\n",
      "Epoch 6/10\n",
      "115/115 [==============================] - 68s 588ms/step - loss: 0.0823 - acc: 0.9906 - val_loss: 0.0556 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.99924\n",
      "Epoch 7/10\n",
      "115/115 [==============================] - 68s 589ms/step - loss: 0.0824 - acc: 0.9904 - val_loss: 0.0553 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99924\n",
      "Epoch 8/10\n",
      "115/115 [==============================] - 68s 589ms/step - loss: 0.0803 - acc: 0.9907 - val_loss: 0.0553 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99924\n",
      "Epoch 9/10\n",
      "115/115 [==============================] - 68s 589ms/step - loss: 0.0814 - acc: 0.9902 - val_loss: 0.0547 - val_acc: 0.9983\n",
      " \n",
      "Epoch 00008: reducing learning rate\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99924\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "new lr: 0.00006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 68s 588ms/step - loss: 0.0784 - acc: 0.9911 - val_loss: 0.0535 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99924\n",
      "Epoch 1/10\n",
      "115/115 [==============================] - 69s 596ms/step - loss: 0.0844 - acc: 0.9903 - val_loss: 0.0568 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.99924\n",
      "Epoch 2/10\n",
      "115/115 [==============================] - 68s 589ms/step - loss: 0.0831 - acc: 0.9907 - val_loss: 0.0565 - val_acc: 0.9994\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.99924 to 0.99938, saving model to drive/NumtaDB/BEST_visual_atention_Callbacks_kfold5_v2.hdf5\n",
      "Epoch 3/10\n",
      "115/115 [==============================] - 68s 589ms/step - loss: 0.0833 - acc: 0.9902 - val_loss: 0.0564 - val_acc: 0.9993\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.99938\n",
      "Epoch 4/10\n",
      "115/115 [==============================] - 68s 589ms/step - loss: 0.0807 - acc: 0.9912 - val_loss: 0.0563 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.99938\n",
      "Epoch 5/10\n",
      "115/115 [==============================] - 68s 589ms/step - loss: 0.0807 - acc: 0.9911 - val_loss: 0.0559 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.99938\n",
      "Epoch 6/10\n",
      "115/115 [==============================] - 68s 588ms/step - loss: 0.0786 - acc: 0.9916 - val_loss: 0.0556 - val_acc: 0.9993\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.99938\n",
      "Epoch 7/10\n",
      "115/115 [==============================] - 68s 589ms/step - loss: 0.0795 - acc: 0.9917 - val_loss: 0.0555 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99938\n",
      "Epoch 8/10\n",
      "115/115 [==============================] - 68s 589ms/step - loss: 0.0805 - acc: 0.9913 - val_loss: 0.0553 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99938\n",
      "Epoch 9/10\n",
      "115/115 [==============================] - 68s 588ms/step - loss: 0.0792 - acc: 0.9915 - val_loss: 0.0551 - val_acc: 0.9992\n",
      " \n",
      "Epoch 00008: reducing learning rate\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99938\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "new lr: 0.00003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 68s 589ms/step - loss: 0.0779 - acc: 0.9916 - val_loss: 0.0548 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99938\n"
     ]
    }
   ],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "from keras.regularizers import l2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.math import add_n\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, GlobalAveragePooling2D\n",
    "from PIL import Image\n",
    "from keras import losses, optimizers, metrics\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import add, concatenate\n",
    "BASE = \"drive/NumtaDB/\"\n",
    "X_train = np.load(BASE+'x_train_all_64.npy')\n",
    "Y_train = np.load(BASE+'x_label_all_64.npy')\n",
    "#X_train = X_train[:len(X_train)//2]\n",
    "#Y_train = Y_train[:len(Y_train)//2]\n",
    "print(len(X_train))\n",
    "print(len(Y_train))\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.layers import Dense, Dropout,  Conv2D, Input, Lambda, Flatten, TimeDistributed\n",
    "from keras.layers import Add, Reshape, MaxPooling2D, Concatenate, Embedding, RepeatVector\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.engine.topology import Layer\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import EarlyStopping\n",
    "import sys\n",
    "\n",
    "aug1 = iaa.GaussianBlur(sigma=(0, 2.0))\n",
    "aug2 = iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5)\n",
    "aug3 = iaa.Multiply((0.8, 1.2), per_channel=0.2)\n",
    "aug4 = iaa.Affine(\n",
    "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "        rotate=(-45, 45),\n",
    "        shear=(-8, 8))\n",
    "\n",
    "aug5 = iaa.CoarseDropout(p=0.2, size_percent = 0.15)\n",
    "aug6 = iaa.ContrastNormalization((0.75, 1.5))\n",
    "aug7 = iaa.Pepper(p=0.05)\n",
    "l2_lambda = 0.0001\n",
    "def augment_img(img):\n",
    "    \n",
    "    i = np.random.randint(0,9)\n",
    "\n",
    "    if i==0:\n",
    "        img_adapteq = img\n",
    "\n",
    "    elif i==1:\n",
    "        img_adapteq = aug4.augment_image(img)\n",
    "        img_adapteq = aug1.augment_image(img_adapteq)\n",
    "\n",
    "    elif i==2:\n",
    "        img_adapteq = aug2.augment_image(img)\n",
    "\n",
    "    elif i==3:\n",
    "        img_adapteq = aug3.augment_image(img)\n",
    "\n",
    "    elif i==4:\n",
    "        img_adapteq = aug4.augment_image(img)  \n",
    " \n",
    "    elif i==5:\n",
    "        img_adapteq = aug5.augment_image(img)  \n",
    "\n",
    "    elif i==6:\n",
    "        img_adapteq = aug6.augment_image(img)  \n",
    " \n",
    "    elif i==7:\n",
    "        img_adapteq = aug4.augment_image(img)\n",
    "        img_adapteq = aug7.augment_image(img_adapteq)\n",
    "        img_adapteq = aug1.augment_image(img_adapteq)\n",
    "\n",
    "    elif i==8:\n",
    "        img_adapteq = aug4.augment_image(img)\n",
    "        img_adapteq = aug2.augment_image(img_adapteq)\n",
    "    \n",
    "    img_adapteq = img_adapteq.astype('float32')\n",
    "    img_adapteq /= 255.\n",
    "\n",
    "    return img_adapteq\n",
    "\n",
    "\n",
    "def MultiHeadsAttModel(l=8*8, d=512, dv=64, dout=512, nv = 8 ): #l=6*6, d=64*3 , dv=8*3, dout=32, nv = 8\n",
    "    v1 = Input(shape = (l, d))\n",
    "    q1 = Input(shape = (l, d))\n",
    "    k1 = Input(shape = (l, d))\n",
    "\n",
    "    v2 = Dense(dv*nv, activation = \"relu\")(v1) # we want every encoding to 64*3 as the initial encoding so dv*nv 8*3*8 W_V\n",
    "    q2 = Dense(dv*nv, activation = \"relu\")(q1) #same W_Q\n",
    "    k2 = Dense(dv*nv, activation = \"relu\")(k1) #same W_K\n",
    "\n",
    "    v = Reshape([l, nv, dv])(v2) # for all the nv attention heads find those components\n",
    "    q = Reshape([l, nv, dv])(q2) \n",
    "    k = Reshape([l, nv, dv])(k2) \n",
    "\n",
    "    att = Lambda(lambda x: K.batch_dot(x[0],x[1] ,axes=[-1,-1]) / np.sqrt(dv),\n",
    "                 output_shape=(l, nv, nv))([q,k])# l, nv, nv\n",
    "    att = Lambda(lambda x:  K.softmax(x) , output_shape=(l, nv, nv))(att)\n",
    "\n",
    "    out = Lambda(lambda x: K.batch_dot(x[0], x[1],axes=[4,3]),  output_shape=(l, nv, dv))([att, v])\n",
    "    out = Reshape([l, d])(out)\n",
    "    \n",
    "    out = Add()([out, q1])\n",
    "\n",
    "    out = Dense(dout, activation = \"relu\")(out)\n",
    "    m = Model(inputs=[q1,k1,v1], outputs=out)\n",
    "    from keras.utils import plot_model\n",
    "    plot_model(m, to_file='m.png', show_shapes=True)\n",
    "    from IPython.display import Image\n",
    "    Image(filename='m.png')\n",
    "    return  Model(inputs=[q1,k1,v1], outputs=out)\n",
    "\n",
    "class NormL(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(NormL, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.a = self.add_weight(name='kernel', \n",
    "                                      shape=(1,input_shape[-1]),\n",
    "                                      initializer='ones',\n",
    "                                      trainable=True)\n",
    "        self.b = self.add_weight(name='kernel', \n",
    "                                      shape=(1,input_shape[-1]),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        super(NormL, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, x):\n",
    "        eps = 0.000001\n",
    "        mu = K.mean(x, keepdims=True, axis=-1)\n",
    "        sigma = K.std(x, keepdims=True, axis=-1)\n",
    "        ln_out = (x - mu) / (sigma + eps)\n",
    "        return ln_out*self.a + self.b\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "class LearningRateDecay(Callback):\n",
    "    '''Learning rate scheduler.\n",
    "    # Arguments\n",
    "        schedule: a function that takes an epoch index as input\n",
    "            (integer, indexed from 0) and returns a new\n",
    "            learning rate as output (float).\n",
    "    '''\n",
    "    def __init__(self, decay, every_n=1, verbose=0):\n",
    "        Callback.__init__(self)\n",
    "        self.decay = decay\n",
    "        self.every_n = every_n\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if not (epoch and epoch % self.every_n == 0):\n",
    "            return\n",
    "\n",
    "        assert hasattr(self.model.optimizer, 'lr'), \\\n",
    "            'Optimizer must have a \"lr\" attribute.'\n",
    "        current_lr = K.get_value(self.model.optimizer.lr)\n",
    "        new_lr = current_lr * self.decay\n",
    "        if self.verbose > 0:\n",
    "            print(' \\nEpoch %05d: reducing learning rate' % (epoch))\n",
    "            sys.stderr.write('new lr: %.5f\\n' % new_lr)\n",
    "        K.set_value(self.model.optimizer.lr, new_lr)\n",
    "              \n",
    "      \n",
    "if __name__ == '__main__':   \n",
    "\n",
    "    nb_classes = 10\n",
    "\n",
    "    # the data, shuffled and split between tran and test sets\n",
    "    #(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    print(\"X_train original shape\", X_train.shape)\n",
    "    print(\"y_train original shape\", Y_train.shape)\n",
    "   \n",
    "    #X_train = X_train.astype('float32')\n",
    "    #X_test = X_test.astype('float32')\n",
    "    #X_train /= 255.0\n",
    "    #X_test /= 255.0\n",
    "    \n",
    "\n",
    "    #Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "    #Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "    \n",
    "    inp = Input(shape = (64,64,3))\n",
    "    x = Conv2D(16, (5, 5), padding='same',activation='relu',kernel_regularizer=l2(l2_lambda))(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(16, (5, 5), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(16, (5, 5), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), padding='same',activation='relu',kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(32, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(32, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), padding='same',activation='relu',kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same',activation='relu',kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64*3, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    #x = GlobalAveragePooling2D()(x)\n",
    "    '''\n",
    "    x = Conv2D(32,(2,2),activation='relu', padding='same')(inp)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(64,(2,2),activation='relu',padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(64,(2,2),activation='relu',padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(64*3,(2,2),activation='relu')(x)\n",
    "    '''\n",
    "    print(x.shape)\n",
    "    \n",
    "    m = Model(inputs = [inp],outputs =  x)\n",
    "    #print(m.summary)\n",
    "    \n",
    "    if True:\n",
    "        x = Reshape([8*8,64*3])(x) #number of words(6*6) * it's encoding(64*3) output by the encoder     \n",
    "        att = MultiHeadsAttModel(l=8*8, d=64*3 , dv=8*3, dout=32, nv = 8 )\n",
    "        x = att([x,x,x])#sent to the decoder to use attention heads to decode \n",
    "        x = Reshape([8,8,32])(x)\n",
    "        x = NormL()(x)\n",
    "    \n",
    "    x = Flatten()(x) \n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    print(model.summary())\n",
    "    from keras.utils import plot_model\n",
    "    plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    from IPython.display import Image\n",
    "    Image(filename='model.png')\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    #tbCallBack = TensorBoard(log_dir='./Graph/mhatt1', histogram_freq=0, write_graph=True, write_images=True)\n",
    "    model.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy', \n",
    "                      metrics = ['accuracy'])\n",
    "    BS = 500\n",
    "    callbacks = [EarlyStopping(monitor='val_acc', patience=20, verbose=1, min_delta=1e-6),\n",
    "             LearningRateDecay(0.5, every_n = 8, verbose=1),\n",
    "             ModelCheckpoint(filepath= BASE + 'BEST_visual_atention_Callbacks_kfold5_v2' + '.hdf5', verbose=1,monitor = 'val_acc',\n",
    "                             save_best_only=True, save_weights_only=True, mode='auto')]\n",
    "    \n",
    "    \n",
    "    X_train_all = X_train.reshape(len(X_train), 64,64,3)\n",
    "    #Y_train_all = X_test.reshape(len(X_test), 64,64,3)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n",
    "    for train_index, test_index in kf.split(X_train_all):\n",
    "        #print(train_index)\n",
    "        X_train = X_train_all[train_index]; X_test = X_train_all[test_index]\n",
    "        y_train = Y_train[train_index]; y_test = Y_train[test_index]\n",
    "        train_datagen = ImageDataGenerator(preprocessing_function=augment_img)\n",
    "        train_datagen.fit(X_train)\n",
    "        model.load_weights(filepath= BASE + 'BEST_visual_atention_Callbacks_kfold5_v2' + '.hdf5')\n",
    "        model.fit_generator(train_datagen.flow(X_train, y_train , batch_size = BS),\n",
    "              epochs=10, verbose=1, validation_data = (X_test.astype('float32')/255.0, y_test),callbacks = callbacks,\n",
    "                    steps_per_epoch=int(len(X_train))//BS,\n",
    "                    validation_steps=int(len(X_test))/BS\n",
    "                   )\n",
    "    \n",
    "    '''\n",
    "    model.fit(X_train, y_train,\n",
    "              batch_size=500, \n",
    "              epochs=100,\n",
    "              verbose=1,          \n",
    "              validation_data=(X_test, y_test)\n",
    "              #callbacks=[tbCallBack]\n",
    "             )\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14779,
     "status": "ok",
     "timestamp": 1566896963523,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD2lkgdC-M_53HbDklxXbBN0K9q5UMGVQMUi_3gQQ=s64",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "vxtQH6MwU72w",
    "outputId": "d37645e8-5683-4bd3-9a35-d7301c5246ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17626\n"
     ]
    }
   ],
   "source": [
    "x_test_all = np.load(BASE+'x_test_all_128.npy')\n",
    "predictions_prob=model.predict(x_test_all)\n",
    "labels=[np.argmax(pred) for pred in predictions_prob]\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y0PCUJ0TVotL"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save_weights(BASE+'attention_accu99445.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15725,
     "status": "ok",
     "timestamp": 1566977183996,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD2lkgdC-M_53HbDklxXbBN0K9q5UMGVQMUi_3gQQ=s64",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "lpyv5yYlYHk4",
    "outputId": "1e135f07-3ea1-4c54-bdcf-adcaf6332da2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 64, 8, 32)\n",
      "(?, 64, 8, 32)\n",
      "(?, 64, 8, 8)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 8 and 32 for 'lambda_53/MatMul' (op: 'BatchMatMulV2') with input shapes: [?,64,8,8], [?,64,8,32].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/dummy_work/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1864\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1865\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 8 and 32 for 'lambda_53/MatMul' (op: 'BatchMatMulV2') with input shapes: [?,64,8,8], [?,64,8,32].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7933b8e8152a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#number of words(6*6) * it's encoding(64*3) output by the encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0matt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiHeadsAttModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#l=8*8, d=64*3 , dv=8*3, dout=32, nv = 8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#sent to the decoder to use attention heads to decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-7933b8e8152a>\u001b[0m in \u001b[0;36mMultiHeadsAttModel\u001b[0;34m(l, d, dv, dout, nv)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;31m#print(att.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;31m#print(v.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 64*24*24 . 64*8*24\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0;31m#print(out.shape) #? 64 32 8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 64*256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dummy_work/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dummy_work/lib/python3.7/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-7933b8e8152a>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;31m#print(att.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;31m#print(v.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 64*24*24 . 64*8*24\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0;31m#print(out.shape) #? 64 32 8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 64*256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dummy_work/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_dot\u001b[0;34m(x, y, axes)\u001b[0m\n\u001b[1;32m   1169\u001b[0m             \u001b[0madj_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0madj_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjoint_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madj_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjoint_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madj_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx_ndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0my_ndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dummy_work/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dummy_work/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2607\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2608\u001b[0m         \u001b[0madjoint_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2609\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_mat_mul_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madjoint_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madjoint_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2611\u001b[0m     \u001b[0;31m# Neither matmul nor sparse_matmul support adjoint, so we conjugate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dummy_work/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mbatch_mat_mul_v2\u001b[0;34m(x, y, adj_x, adj_y, name)\u001b[0m\n\u001b[1;32m   1675\u001b[0m   \u001b[0madj_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"adj_y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 1677\u001b[0;31m         \"BatchMatMulV2\", x=x, y=y, adj_x=adj_x, adj_y=adj_y, name=name)\n\u001b[0m\u001b[1;32m   1678\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1679\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dummy_work/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dummy_work/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/envs/dummy_work/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3614\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3615\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3616\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3617\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3618\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dummy_work/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2025\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   2026\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 2027\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   2028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dummy_work/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 8 and 32 for 'lambda_53/MatMul' (op: 'BatchMatMulV2') with input shapes: [?,64,8,8], [?,64,8,32]."
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout,  Conv2D, Input, Lambda, Flatten, TimeDistributed\n",
    "from keras.layers import Add, Reshape, MaxPooling2D, Concatenate, Embedding, RepeatVector\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.engine.topology import Layer\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import EarlyStopping\n",
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from imgaug import augmenters as iaa\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "BASE = \"drive/NumtaDB/\"\n",
    "aug1 = iaa.GaussianBlur(sigma=(0, 2.0))\n",
    "aug2 = iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5)\n",
    "aug3 = iaa.Multiply((0.8, 1.2), per_channel=0.2)\n",
    "aug4 = iaa.Affine(\n",
    "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "        rotate=(-45, 45),\n",
    "        shear=(-8, 8))\n",
    "\n",
    "aug5 = iaa.CoarseDropout(p=0.2, size_percent = 0.15)\n",
    "aug6 = iaa.ContrastNormalization((0.75, 1.5))\n",
    "aug7 = iaa.Pepper(p=0.05)\n",
    "l2_lambda = 0.0001\n",
    "#x_test_all = np.load(BASE+'x_test_all_128.npy')\n",
    "def augment_img(img):\n",
    "    \n",
    "    i = np.random.randint(0,9)\n",
    "\n",
    "    if i==0:\n",
    "        img_adapteq = img\n",
    "\n",
    "    elif i==1:\n",
    "        img_adapteq = aug4.augment_image(img)\n",
    "        img_adapteq = aug1.augment_image(img_adapteq)\n",
    "\n",
    "    elif i==2:\n",
    "        img_adapteq = aug2.augment_image(img)\n",
    "\n",
    "    elif i==3:\n",
    "        img_adapteq = aug3.augment_image(img)\n",
    "\n",
    "    elif i==4:\n",
    "        img_adapteq = aug4.augment_image(img)  \n",
    " \n",
    "    elif i==5:\n",
    "        img_adapteq = aug5.augment_image(img)  \n",
    "\n",
    "    elif i==6:\n",
    "        img_adapteq = aug6.augment_image(img)  \n",
    " \n",
    "    elif i==7:\n",
    "        img_adapteq = aug4.augment_image(img)\n",
    "        img_adapteq = aug7.augment_image(img_adapteq)\n",
    "        img_adapteq = aug1.augment_image(img_adapteq)\n",
    "\n",
    "    elif i==8:\n",
    "        img_adapteq = aug4.augment_image(img)\n",
    "        img_adapteq = aug2.augment_image(img_adapteq)\n",
    "    \n",
    "    img_adapteq = img_adapteq.astype('float32')\n",
    "    img_adapteq /= 255.\n",
    "\n",
    "    return img_adapteq\n",
    "\n",
    "\n",
    "def MultiHeadsAttModel(l=8*8, d=64*4 , dv=8*4, dout=32, nv = 8): #l=8*8, d=nv*dv, dv=64, dout=32, nv = 8\n",
    "                                                                  # l=8*8, d=nv*dv , dv=8*4, dout=32, nv = 8 \n",
    "    v1 = Input(shape = (l, d))\n",
    "    q1 = Input(shape = (l, d))\n",
    "    k1 = Input(shape = (l, d)) #N \n",
    "    \n",
    "    v2 = Dense(dv*nv, activation = \"relu\")(v1) # we want every encoding to 64*3 as the initial encoding so dv*nv 8*3*8 W_V\n",
    "    q2 = Dense(dv*nv, activation = \"relu\")(q1) #same W_Q\n",
    "    k2 = Dense(dv*nv, activation = \"relu\")(k1) #same W_K\n",
    "\n",
    "    v = Reshape([l, nv, dv])(v2) # for all the nv attention heads find those components\n",
    "    q = Reshape([l, nv, dv])(q2) \n",
    "    k = Reshape([l, nv, dv])(k2) \n",
    "    #print(q.shape)\n",
    "    # print(q.shape) #? 64 8 24 ##64*8*32\n",
    "    att = Lambda(lambda x: K.batch_dot(x[0],x[1] ,axes=[3,3]) / np.sqrt(dv),\n",
    "                 output_shape=(l, nv, nv))([q,k])# l, nv, nv\n",
    "    print(q.shape)\n",
    "    print(k.shape)\n",
    "    print(att.shape)  #? 64 32 32 \n",
    "    att = Lambda(lambda x:  K.softmax(x) , output_shape=(l, nv, nv))(att)\n",
    "    #print(att.shape) \n",
    "    #print(v.shape)\n",
    "    out = Lambda(lambda x: K.batch_dot(x[0], x[1],axes=[4,3]),output_shape=(l, nv, dv))([att, v]) # 64*24*24 . 64*8*24\n",
    "    #print(out.shape) #? 64 32 8 \n",
    "    out = Reshape([l, d])(out) # 64*256\n",
    "    \n",
    "    out = Add()([out, q1])\n",
    "    \n",
    "    out = Dense(dout, activation = \"relu\")(out)\n",
    "    #print(out.shape)\n",
    "    m = Model(inputs=[q1,k1,v1], outputs=out)\n",
    "    '''\n",
    "    from keras.utils import plot_model\n",
    "    plot_model(m, to_file='m.png', show_shapes=True)\n",
    "    from IPython.display import Image\n",
    "    Image(filename='m.png')\n",
    "    '''\n",
    "    return  Model(inputs=[q1,k1,v1], outputs=out)\n",
    "\n",
    "class NormL(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(NormL, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.a = self.add_weight(name='kernel', \n",
    "                                      shape=(1,input_shape[-1]),\n",
    "                                      initializer='ones',\n",
    "                                      trainable=True)\n",
    "        self.b = self.add_weight(name='kernel', \n",
    "                                      shape=(1,input_shape[-1]),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        super(NormL, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, x):\n",
    "        eps = 0.000001\n",
    "        mu = K.mean(x, keepdims=True, axis=-1)\n",
    "        sigma = K.std(x, keepdims=True, axis=-1)\n",
    "        ln_out = (x - mu) / (sigma + eps)\n",
    "        return ln_out*self.a + self.b\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "      \n",
    "def get_key(path):\n",
    "    # seperates the key of an image from the filepath\n",
    "    key=path.split(sep=os.sep)[-1]\n",
    "    return key\n",
    "  \n",
    "def create_submission(predictions,keys,path):\n",
    "    result = pd.DataFrame(\n",
    "        predictions,\n",
    "        columns=['label'],\n",
    "        index=keys\n",
    "        )\n",
    "    result.index.name='key'\n",
    "    result.to_csv(path, index=True)\n",
    "    \n",
    "class LearningRateDecay(Callback):\n",
    "    '''Learning rate scheduler.\n",
    "    # Arguments\n",
    "        schedule: a function that takes an epoch index as input\n",
    "            (integer, indexed from 0) and returns a new\n",
    "            learning rate as output (float).\n",
    "    '''\n",
    "    def __init__(self, decay, every_n=1, verbose=0):\n",
    "        Callback.__init__(self)\n",
    "        self.decay = decay\n",
    "        self.every_n = every_n\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if not (epoch and epoch % self.every_n == 0):\n",
    "            return\n",
    "\n",
    "        assert hasattr(self.model.optimizer, 'lr'), \\\n",
    "            'Optimizer must have a \"lr\" attribute.'\n",
    "        current_lr = K.get_value(self.model.optimizer.lr)\n",
    "        new_lr = current_lr * self.decay\n",
    "        if self.verbose > 0:\n",
    "            print(' \\nEpoch %05d: reducing learning rate' % (epoch))\n",
    "            sys.stderr.write('new lr: %.5f\\n' % new_lr)\n",
    "        K.set_value(self.model.optimizer.lr, new_lr)\n",
    "              \n",
    "if __name__ == '__main__':   \n",
    "\n",
    "    nb_classes = 10\n",
    "\n",
    "    # the data, shuffled and split between tran and test sets\n",
    "    #(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    #print(\"X_train original shape\", X_train.shape)\n",
    "    #print(\"y_train original shape\", Y_train.shape)\n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)\n",
    "    X_train = X_train.reshape(len(X_train), 64,64,3)\n",
    "    X_test = X_test.reshape(len(X_test), 64,64,3)\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(preprocessing_function=augment_img)\n",
    "    train_datagen.fit(X_train)\n",
    "    '''\n",
    "    \n",
    "    #X_train = X_train.astype('float32')\n",
    "    #X_test = X_test.astype('float32')\n",
    "    #X_train /= 255.0\n",
    "    #X_test /= 255.0\n",
    "    #print(\"Training matrix shape\", X_train.shape)\n",
    "    #print(\"Testing matrix shape\", X_test.shape)\n",
    "\n",
    "    #Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "    #Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "    \n",
    "    inp = Input(shape = (64,64,3))\n",
    "    x = Conv2D(16, (5, 5), padding='same',activation='relu',kernel_regularizer=l2(l2_lambda))(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(16, (5, 5), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(16, (5, 5), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), padding='same',activation='relu',kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(32, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(32, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), padding='same',activation='relu',kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same',activation='relu',kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64*3, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    #x = GlobalAveragePooling2D()(x)\n",
    "    '''\n",
    "    x = Conv2D(32,(2,2),activation='relu', padding='same')(inp)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(64,(2,2),activation='relu',padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(64,(2,2),activation='relu',padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(64*3,(2,2),activation='relu')(x)\n",
    "    '''\n",
    "    #print(x.shape)\n",
    "    \n",
    "    m = Model(inputs = [inp],outputs =  x)\n",
    "    #print(m.summary)\n",
    "    \n",
    "    if True:\n",
    "        x = Reshape([8*8,64*3])(x) #number of words(6*6) * it's encoding(64*3) output by the encoder     \n",
    "        att = MultiHeadsAttModel(l=8*8, d=64*4 , dv=8*4, dout=32, nv = 8)#l=8*8, d=64*3 , dv=8*3, dout=32, nv = 8 \n",
    "        x = att([x,x,x])#sent to the decoder to use attention heads to decode \n",
    "        x = Reshape([8,8,32])(x)\n",
    "        x = NormL()(x)\n",
    "    \n",
    "    x = Flatten()(x) \n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    '''\n",
    "    print(model.summary())\n",
    "    from keras.utils import plot_model\n",
    "    plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    from IPython.display import Image\n",
    "    Image(filename='model.png')\n",
    "    '''\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    #tbCallBack = TensorBoard(log_dir='./Graph/mhatt1', histogram_freq=0, write_graph=True, write_images=True)\n",
    "    model.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy', \n",
    "                      metrics = ['accuracy'])\n",
    "    \n",
    "    #model.load_weights(BASE+'BEST_visual_atention_Callbacks_kfold5_v2.hdf5')\n",
    "    '''\n",
    "    x_test_all = np.load(BASE+'x_test_all_128.npy')\n",
    "    with open(BASE+'mylist_paths', 'rb') as f:\n",
    "        paths_test_all = pickle.load(f)\n",
    "        paths_test_all = sorted(paths_test_all)\n",
    "    predictions_prob=model.predict(x_test_all/255.0)\n",
    "    labels=[np.argmax(pred) for pred in predictions_prob]\n",
    "    print(len(labels))\n",
    "    keys=[get_key(path) for path in paths_test_all]\n",
    "    create_submission(predictions=labels,keys=keys,path=BASE+'submission7.csv')\n",
    "    \n",
    "    \n",
    "    BS = 500\n",
    "    callbacks = [EarlyStopping(monitor='val_acc', patience=100, verbose=1, min_delta=1e-6),\n",
    "             LearningRateDecay(0.5, every_n = 8, verbose=1),\n",
    "             ModelCheckpoint(filepath= BASE + 'BEST_visual_atention_Callbacks_2nd' + '.hdf5', verbose=1,monitor = 'val_acc',\n",
    "                             save_best_only=True, save_weights_only=False, mode='auto')]\n",
    "    \n",
    "    model.fit_generator(train_datagen.flow(X_train, y_train , batch_size = BS),\n",
    "              epochs=200, verbose=1, validation_data = (X_test.astype('float32')/255.0, y_test),callbacks = callbacks,\n",
    "                    steps_per_epoch=int(len(X_train))//BS,\n",
    "                    validation_steps=int(len(X_test))/BS\n",
    "                   )\n",
    "    \n",
    "    model.fit(X_train, y_train,\n",
    "              batch_size=500, \n",
    "              epochs=100,\n",
    "              verbose=1,          \n",
    "              validation_data=(X_test, y_test)\n",
    "              #callbacks=[tbCallBack]\n",
    "             )\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2802,
     "status": "ok",
     "timestamp": 1566977519454,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD2lkgdC-M_53HbDklxXbBN0K9q5UMGVQMUi_3gQQ=s64",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "tTG46rU4nTHF",
    "outputId": "2c67f502-d1d7-4f51-d590-cad4f17938f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "testing-augc/augc00625.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fde3ebe9400>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGl1JREFUeJztnX/MFdWZx79fQQWVgsgrfSsirlqV\ntFbrW7ShbVRWo64ptmlI62bDbmj4p7ux2W6q3U02bbKbtP/0xx+73dC1K03a+qPY1ZpGyyLUkG7V\nV6EtiAgiVigIWKjUKgo8+8edO56Zfe/cc+eembmX8/0kb94zc86c89y589x5nvPjOTQzCCHi4qSm\nBRBC1I8UX4gIkeILESFSfCEiRIovRIRI8YWIECm+EBHSl+KTvJHkVpLbSd4ZSighRLWw7AQekpMA\nPA/gegC7ADwF4DNm9mw48YQQVTC5j2sXANhuZjsAgOQ9ABYD6Kj4s2bNsrlz5wIATjpp8L2M/I8i\nyYYkEcKPnTt34sCBA10f1H4U/xwALzvHuwBcVXTB3LlzsX79egDA1KlTO5YrUjBXGY8fP+59nZvn\npvPKXVS/+2NVVIevTFUTQsYQn82to4r7UUbGXizdMp+zl/o63Z9enu92HQsWLPCSofLXLsnlJMdJ\njh84cKDq5oQQHvTzxt8N4FzneE5yLoOZrQCwAgCuvPJKa781ezGjO/2S5q8J8cvc6a3ere06KXqT\nd5KrrLy+1lGT98rXsul0TZNyFMlS5T3t543/FICLSJ5P8hQAnwbwUF/SCCFqofQb38yOkvxbAI8C\nmATgu2a2OZhkQojK6MfUh5n9FMBPA8kihKiJvhS/VIOTW0324tOH9luLfFNfv7XqACaDOGqg4czy\nlLl3VT5/gz+YLoQIjhRfiAip3dQfBEKYrMNmYhcNxdU5i7KKiTP9XlMFdQ5hlkFvfCEiRIovRIRI\n8YWIkFp9fJKNrcrrNEwXywq8os85KMOFojy9Du/pjS9EhEjxhYiQ2ofz2iZJ3SZ/7CbroAY+Gbbv\n5URxDQfzaRBCVIoUX4gIqdXUN7O+FxdUHWihzCKdEG31U88g4hs8perQXqGfF9/6q5htWTbQx0To\njS9EhEjxhYgQKb4QEVL7zL1+fZ8mVz2FDhNdNgjIMFNFv0ZI37cbJ0q/jN74QkSIFF+ICBm6QBx1\n7spShdlfdF2Zz1PW9HSvK6qj6l1kQlO36V3l81jlZ9EbX4gIkeILESFSfCEipDEfv+zeeXUG0fD1\nW3uRo+q96MpMIQ3tx5etv6i9YR02q4qyU5PbdH3jk/wuyX0kNznnZpJcTXJb8v/MnloVQjSKj6l/\nN4Abc+fuBLDGzC4CsCY5FkIMCV1NfTN7nOS83OnFAK5J0isBrANwh0ddqUkSYpXWoMSKz1O1SVzG\nBenF1A8x+62TS9OLyR6ijljo9Z6U1Y7ZZrYnSe8FMLtkPUKIBuj7tWitn+KOrwiSy0mOkxw/cOBA\nv80JIQJQtlf/FZKjZraH5CiAfZ0KmtkKACsA4MorrzSfXuciE77TNRO061W2ioAJdVJFj3yIRS+d\nris7klFUR4gZj/3W1zR1hdd+CMDSJL0UwIMl6xFCNIDPcN4PAfwvgItJ7iK5DMBXAVxPchuAP0+O\nhRBDgk+v/mc6ZC0KLIsQoiYGZuZene0Nqg9X5+quotV5VVJ2RWKRjKG/27r7Q3zq7la/ttASQnRF\nii9EhNRu6oc0Z4tMId9ZfYNk9pcxFcvKX8ZEDRGzvsmhzxAzKo8dO5bJCz1DNMRiKh/0xhciQqT4\nQkSIFF+ICBmKYJtl9zUrU0cImozz3kmOXq4LUX8ZyvYhVN034rvqs+pnLOSzpDe+EBEixRciQmo3\n9ftdadfk8JuvHMePH/cqlyf0EFtZU/nNN9+csNyUKVO85fAt5+tKFJVzze8Qqwl7mV1Ypj3f1YXa\nJlsIERQpvhARMjC9+qG3lirTbre2ygTzePvttzPHv//979P0rFmzMnmTJk3qWE+V5OWfOnWqVznf\nbbg6XdNLXhGhZxCGWKQTIqR4UZ5vsJpO6I0vRIRI8YWIECm+EBHS2Oq8KmK5+7RbR1sumzdvzhy7\nkYYXLlyYyXOHy3x9RHfoEOg8tFU2QGXZ+xZiNl2IIKshhtuK2vYNKhpi9mnIWZR64wsRIVJ8ISKk\ndlO/bZrmTdQ6F3xUHb/96NGjafrw4cOZvAsuuCBNdxo264UQJmQRvvctxFCc70y1ENuv5c+XnW3p\ni6/8Ve9c3EZvfCEiRIovRIRI8YWIkNp9/H6DE4ZYzVX11FDXX5w2bVom7+yzzy7VtovvPoO+06CL\n+luq3vK7TH1VyFRUf+jPUnbVnVsuP707+JRdkueSXEvyWZKbSd6enJ9JcjXJbcn/M3tqWQjRGD6v\n36MAvmBm8wFcDeBzJOcDuBPAGjO7CMCa5FgIMQT47J23B8CeJH2Y5BYA5wBYDOCapNhKAOsA3FFU\nF8nUXAkdj7wbZVaL+Q4b5U3lN954I00fPHgwk3fyySf3LGOe0LPRiijrPnX6fvP3qiieXYjtr32D\ndLhtVTFsWYYqV6X2pH0k5wG4AsATAGYnPwoAsBfA7KCSCSEqw1vxSZ4BYBWAz5vZa26etX4GJ/wp\nJLmc5DjJ8f379/clrBAiDF6KT/JktJT++2b2QHL6FZKjSf4ogH0TXWtmK8xszMzGRkZGQsgshOiT\nrj4+W47GXQC2mNnXnayHACwF8NXk/4Pd6jKzdO+xsvHJy/pfvtMiy/hV+aGV1157xyCaMWNGJq/I\nx/dd6eUS4l75TiEN4XNWHV0p34fgTp8uuvex4TOOvxDAXwH4DcmNybl/REvh7yO5DMBLAJZUI6IQ\nIjQ+vfrrAXT6WV4UVhwhRB0M3cy9InxN2ypm9bm4pn5+BV6ZYaMqgpaEmAmX3zLap62ivCpcCdcN\n853xWAVNtj0RmqsvRIRI8YWIkMYCcVQdQ75J0+0Pf/hDmj7jjDM61lF2wVGI7cbKzBLMX+M7K87d\nW2Dnzp2ZvO3bt6fp8847L5P3nve8J01Pnz69oxwuRaMGoV2kfJ2hg4VUid74QkSIFF+ICJHiCxEh\ntfr4JDF5cn9NlvVhfWO0h972uJfVeGW2uM7Tabi0aAgpPyznzn5zv698Obet/Gf505/+lKZXrVqV\npteuXZsp586sy8voBi357Gc/m6bf+973Zsp1GrKrgipmUTaB3vhCRIgUX4gIGZhtsl2KzNKyJlOZ\nuGa+sdHyJrC7FfZZZ51VSo4Q+M5QzA+tusdF5dw812QHgNWrV6fpRx55JE2feWY2QtucOXM61v/y\nyy+n6e985ztpevny5ZlyedPfpZPr08tzVObZKSL081cGvfGFiBApvhARIsUXIkIa2yY7BCHin4fw\n2fJ+ZNF0ZF/fLPSwZdkVib5+5Ysvvpg5XrduXZq+9NJL0/TcuXMz5RYsWJCmR0dHM3kPPPBAml6/\nfn2afuyxxzLl3H6C/BTpEM9b6L6YssO4+SAj/aA3vhARIsUXIkIaW50XIoZ6iKG9XvA1o48cOZKm\ny5pnIeK8+26hVXbY6M0330zT7vAdkDXv3Vl88+fPz5Q799xz0/Tpp5+eyVu8eHGafuWVV9K0u6IP\nAPbu3ZumL7zwwkxemaHgqlfWhZ6VWaZOvfGFiBApvhARMjC9+oMWqKAX8vK5C1v++Mc/ZvKKtowK\nTVGgjDK9/PnPeeDAgTQ9a9asTN5pp52Wpjds2JCmXfcAKA5U4tZ58803p+n7778/U27Lli1pOm/q\n+y5aqiKke79UEWuxjd74QkSIFF+ICJHiCxEhjfn4VfovVdHJ18v7ke9617vS9Ouvv57JK5qlVWdf\nRhm/Nb8K8dVXX03T+a3C9uzZk6ZfeumlNJ3vC/DFDcoxZcqUTN7u3bvTdH6VoBsIJfQwbr7Osv1U\nvs9+ravzSE4h+STJX5HcTPIryfnzST5BcjvJe0me0pckQoja8DH1jwC4zsw+AOByADeSvBrA1wB8\nw8wuBHAQwLLqxBRChMRn7zwD0B6TOjn5MwDXAbgtOb8SwJcBfNujPgC97ZrqO/sqdDlfiuo4ePBg\n5tidyZd3EXyH0crQi6nZyaR0Z8jlj93Y+QAwPj6ept1gJO5MvW502qKraJssX/epbCCOEOVCuA79\n4tW5R3JSslPuPgCrAbwA4JCZtR2qXQDOqUZEIURovBTfzI6Z2eUA5gBYAOAS3wZILic5TnJ8//79\nJcUUQoSkp+E8MzsEYC2ADwOYQbLtKswBsLvDNSvMbMzMxkZGRvoSVggRhq4+PskRAG+b2SGSUwFc\nj1bH3loAnwJwD4ClAB7sVpeZpX5bFavFQgdF9CXf1syZM9P0M888k8lzp/DmA0926nsouh8hhkV9\nA0OsWbMmU+6tt95K06eckh3U2bdvX5q+5ZZb0nR+BV4Rbh+I21eSD3Ti3seq92QsS5nnscrhXZ9x\n/FEAK0lOQstCuM/MHib5LIB7SP4LgA0A7qpMSiFEUHx69X8N4IoJzu9Ay98XQgwZjW2hFWK7oUHd\nssiNK5c3bd2Y+/nZbr4mX+jhSN+Veu7230B2dl5+2NL93G5cvbLbWLuuRH6vAjfoR5OmfuiZe1Wu\nCtRcfSEiRIovRIQMXcy9Omfk+ZJva9q0aWn6vPPOy+Rt27YtTc+bNy+T52um+vb4h8CdkeduaQUA\nv/3tbzu2e/3116dpd4urXkYhXNfi6aefTtNTp07NlHODbxTV78b+yy/0qdNFKPrOfGM05uvoNaiL\n3vhCRIgUX4gIkeILESEDs0126K2wB4ULLrggc+xuBeUGqwSA2bNn91x/1UN9ro//xhtvZPJcvzgf\n5PLWW2+dsFwRef9206ZNaXrHjh1p2g28Cfx/f93FvQduANAqKOp7Kbslmm85xdUXQnRFii9EhAyM\nqT+IZnpZ3M+SDzzhxo7buHFjJu/aa69N0/lFL2Xa9p1JVnTvXTN6bGwsk+cOt7kLcYDsQiWXIpl+\n97vfZY6ffPLJNO0OkebdCl+aHOItE1evF2TqCyG6IsUXIkKk+EJEyMD4+CcqeV/9kkveiVr285//\nPJPnTku94op3VkKfeuqpHesv60v6Di+5celvu+22TJ57nVuuSI58W4cPH07TP/nJTzJ5btz+pUuX\npun8fnuDsldBEWWCaGp1nhAiKFJ8ISKkdlO/6q2hBx13RV4+6vBjjz2Wpo8cOZKmP/rRj2bKFW1/\n7bsNeRkTOG/OF9XfKS+/Tfa6devSdH7138KFC9N02SG8WNBwnhCiK1J8ISKkVlPfDa/djr3n5rUZ\nlJ5YX8qGA3/f+96XOX7uuefS9KpVq9L0iy++mCn3yU9+Mk1Pnz69UJZOhF4UVdSuG1L83nvvzeS9\n8MILaTpvzi9atChND5uL2EtI9DL0sgXdRAzX3RRCBEGKL0SESPGFiJDa4+oPm6/mQy+z54oCQ7jB\nK1y/2N1yGsj6/J/4xCcyeZdddlmaLto+uoy8ReSDaOze/c5Wit/73vfSdD74iDtD0f38QHGAjUGn\n6gApeSobzku2yt5A8uHk+HyST5DcTvJekuXWkQohaqeX1+/tALY4x18D8A0zuxDAQQDLQgomhKgO\nL1Of5BwAfwHgXwH8PVu2ynUA2qs2VgL4MoBvd6vLxyQpilc2DK6C7zBXPs8NNrFkyZI0/eijj2bK\nPf/882n67rvvzuS5pv4NN9yQpkdHRzPliuLgdZK/PRTbZu/evWn68ccfz+T98pe/nPA6N9gIANx0\n001p2ncn3X4XqDTBoA1X+2rRNwF8EUDbkTsLwCEzO5oc7wJwTmDZhBAV0VXxSd4CYJ+ZPd2tbIfr\nl5McJzmen5suhGgGnzf+QgAfJ7kTwD1omfjfAjCDZNtVmANg90QXm9kKMxszs7GRkZEAIgsh+oW9\n+EskrwHwD2Z2C8n7Aawys3tI/geAX5vZvxddPzY2Zk899VTvQg6AT9QkR48ezRxv3749Tf/iF7/I\n5LnbcLvTot/97ndnyrnH+UAf7jPhxtLfunVrppwb9z4vozv91t1H7/3vf3+mnG9fQ51UHcyjivrb\ndX7oQx/C+Ph41wr76Sm7A62Ovu1o+fx39VGXEKJGeprAY2brAKxL0jsALAgvkhCiamoPxNE2SXpZ\nXTRoQyF1k1/JePHFF6fpOXPmZPI2bNiQprdseWfaRT7IhesS5GPguyv+3Bl5eRPVHTq86qqrMnmX\nXnppmu4lZmDs1PWsD/6guBAiOFJ8ISKkdlO/bb70YsbIHOxMPtS0G5/PNb9fe+21TLlDhw6l6alT\np2by3MVDbl7e5XB75If9O2rSnWxip2i98YWIECm+EBEixRciQhrz8UV5fO+hu33XrFmzMnn549jx\nvachgpYMVSAOIcSJgxRfiAjRbrlCdGEYAn9oOE8I0RUpvhARIsUXIkIaW52XR6vzwqP7FoZBvHdF\nAWl90BtfiAiR4gsRIY0N5/ma9icaw2x+Vx2Lrqi9YbtXdaPhPCFEV6T4QkTIwMzcKzLrTiTTf5hN\n1rplH+Z7VTX96oje+EJEiBRfiAiR4gsRIQMzc0+E50TykcsO7fk+byfSvfLBS/GTDTMPAzgG4KiZ\njZGcCeBeAPMA7ASwxMwOViOmECIkvZj615rZ5WY2lhzfCWCNmV0EYE1yLIQYAvrx8RcDWJmkVwK4\n1ecikl3/RMtEbf+J8vg8byQz9zv/dyLiq/gG4Gcknya5PDk328z2JOm9AGYHl04IUQm+nXsfMbPd\nJM8GsJrkc26mmRnJCX8akx+K5QAwd+7cvoQVQoTB641vZruT//sA/Bit7bFfITkKAMn/fR2uXWFm\nY2Y2NjIyEkZqIURfdFV8kqeTnNZOA7gBwCYADwFYmhRbCuDBfgQp8qnk/4sQxObHF+Fj6s8G8ONE\n6SYD+IGZPULyKQD3kVwG4CUAS6oTUwgRkq6Kb2Y7AHxggvOvAlhUhVBCiGoZmNV5sZjxvlswDfv9\nCBFEo1MdvWxjFTqYR1m3YNC+T83VFyJCpPhCRIgUX4gIGRgfX5xYhPBpjx07lqYnT37nUR2kQK1l\nttceBH9fb3whIkSKL0SEDIWpP2hmUj+Elr/OWPd1x9WfNGlSz9dULdOguBn9tqU3vhARIsUXIkIG\nJuae78wskaWK2WidvoteYrmHkGvY3Lo6n+F+743e+EJEiBRfiAiR4gsRIQMznHciDdk1SZX3se7h\nvGGm7ntz/PjxnsrrjS9EhEjxhYiQgTH1B8VsHBSXo+xQWRmZqw5eUUTVbfkMHxeVy5etegizSKYi\nOXptW298ISJEii9EhEjxhYiQxnz8QfTpgcGRa1DkCE2Rj1yF/9zJL+5lSu0gTiHvpY9iIvTGFyJC\npPhCREhjq/MGxcSuenXbMFB2dV7VhJCjjJk+KN9nlS6G1xuf5AySPyL5HMktJD9McibJ1SS3Jf/P\nrExKIURQfE39bwF4xMwuQWs7rS0A7gSwxswuArAmORZCDAFdTX2S0wF8DMBfA4CZvQXgLZKLAVyT\nFFsJYB2AO6oQchDxDVBRtVla9Wy3qoNL+MpfNtZdp+uqNudDbLWVl6numXvnA9gP4L9IbiD5n8l2\n2bPNbE9SZi9au+oKIYYAH8WfDOCDAL5tZlcAeB05s95aPz8T/sSRXE5ynOT4/v37+5VXCBEAH8Xf\nBWCXmT2RHP8IrR+CV0iOAkDyf99EF5vZCjMbM7OxkZGREDILIfqkq49vZntJvkzyYjPbCmARgGeT\nv6UAvpr8f9CnwWEb6nIp4/vW7UuGXp1XNthmnYSIdR/is/jODDzppM7v27J9R73K7zuO/3cAvk/y\nFAA7APwNWtbCfSSXAXgJwJKeWhZCNIaX4pvZRgBjE2QtCiuOEKIOGpu5lzd3ypgxZYfRypTrVtaX\n0DPhfE28qtsqe6/K3I8QQ2VFdebrDyGje10+Pp7vkGNRnhbpCCG6IsUXIkKk+EJESO0+fqehjDIB\nJHvxK0P41mX86RABE0MEqBiU6bZlA3GEoGx/SJF/3qlc/jl3r8vX4ZYtGupTsE0hRF9I8YWIENY5\n+4rkfrQm+8wCcKC2hidmEGQAJEceyZGlVznOM7Ouc+NrVfy0UXLczCaaEBSVDJJDcjQlh0x9ISJE\nii9EhDSl+CsaatdlEGQAJEceyZGlEjka8fGFEM0iU1+ICKlV8UneSHIrye0ka4vKS/K7JPeR3OSc\nqz08OMlzSa4l+SzJzSRvb0IWklNIPknyV4kcX0nOn0/yieT7uTeJv1A5JCcl8RwfbkoOkjtJ/obk\nRpLjybkmnpFaQtnXpvgkJwH4NwA3AZgP4DMk59fU/N0AbsydayI8+FEAXzCz+QCuBvC55B7ULcsR\nANeZ2QcAXA7gRpJXA/gagG+Y2YUADgJYVrEcbW5HK2R7m6bkuNbMLneGz5p4RuoJZW9mtfwB+DCA\nR53jLwH4Uo3tzwOwyTneCmA0SY8C2FqXLI4MDwK4vklZAJwG4BkAV6E1UWTyRN9Xhe3PSR7m6wA8\nDIANybETwKzcuVq/FwDTAbyIpO+tSjnqNPXPAfCyc7wrOdcUjYYHJzkPwBUAnmhClsS83ohWkNTV\nAF4AcMjMjiZF6vp+vgngiwDaK1fOakgOA/Azkk+TXJ6cq/t7qS2UvTr3UBwevApIngFgFYDPm9lr\nTchiZsfM7HK03rgLAFxSdZt5SN4CYJ+ZPV132xPwETP7IFqu6OdIfszNrOl76SuUfS/Uqfi7AZzr\nHM9JzjWFV3jw0JA8GS2l/76ZPdCkLABgZocArEXLpJ5Bsr1Uu47vZyGAj5PcCeAetMz9bzUgB8xs\nd/J/H4Afo/VjWPf30lco+16oU/GfAnBR0mN7CoBPA3ioxvbzPIRWWHCgh/Dg/cDWoum7AGwxs683\nJQvJEZIzkvRUtPoZtqD1A/CpuuQwsy+Z2Rwzm4fW8/CYmf1l3XKQPJ3ktHYawA0ANqHm78XM9gJ4\nmeTFyal2KPvwclTdaZLrpLgZwPNo+ZP/VGO7PwSwB8DbaP2qLkPLl1wDYBuA/wEwswY5PoKWmfZr\nABuTv5vrlgXAZQA2JHJsAvDPyfk/A/AkgO0A7gdwao3f0TUAHm5CjqS9XyV/m9vPZkPPyOUAxpPv\n5r8BnFmFHJq5J0SEqHNPiAiR4gsRIVJ8ISJEii9EhEjxhYgQKb4QESLFFyJCpPhCRMj/Aa54Vrfi\n8oV6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(model.predict(np.array([X_test_all[-100]])))\n",
    "ll=np.argmax(model.predict(np.array([x_test_all[6282]/255.0])))\n",
    "print(ll)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(paths_test_all[6282])\n",
    "plt.imshow(x_test_all[6282], cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1213,
     "status": "ok",
     "timestamp": 1566977297019,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD2lkgdC-M_53HbDklxXbBN0K9q5UMGVQMUi_3gQQ=s64",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "ScqrayUyZ_9_",
    "outputId": "e719fb30-65b9-4296-8ce0-858ed0954208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1720, 1717, 1721, 1737, 2049, 1758, 1736, 1723, 1729, 1736]\n"
     ]
    }
   ],
   "source": [
    "a = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "for i in labels:\n",
    "  a[i]+=1\n",
    "print(a)\n",
    "#[0, 3, 0, 31, 10, 16765, 284, 3, 138, 392]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1221,
     "status": "error",
     "timestamp": 1566897539406,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD2lkgdC-M_53HbDklxXbBN0K9q5UMGVQMUi_3gQQ=s64",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "So6SDvHN80JQ",
    "outputId": "ff07a6cf-45c8-4f90-d225-f888b7682f8f"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-8e5a5cca474e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# returns a compiled model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# identical to the previous one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'attention_accu99445.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mx_test_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'x_test_all_128.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpredictions_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[0;34m(f, custom_objects, compile)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot create group in read only mode.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot create group in read only mode."
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "#model.save(BASE+'models/'+'visual_attention_all_cnn_NUMTA_DB.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "#del model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "m = load_model(BASE+'attention_accu99445.hdf5')\n",
    "x_test_all = np.load(BASE+'x_test_all_128.npy')\n",
    "predictions_prob=mod.predict(x_test_all)\n",
    "labels=[np.argmax(pred) for pred in predictions_prob]\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bXNgwhA0Z9tK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11971,
     "status": "ok",
     "timestamp": 1566972057451,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD2lkgdC-M_53HbDklxXbBN0K9q5UMGVQMUi_3gQQ=s64",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "_HZiykRCOFFB",
    "outputId": "3d298b14-142d-4500-abd9-ca1f7c4a90af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train original shape (60000, 28, 28)\n",
      "y_train original shape (60000,)\n",
      "Training matrix shape (60000, 28, 28, 1)\n",
      "Testing matrix shape (10000, 28, 28, 1)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_23 (InputLayer)           (None, 36, 192)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           (None, 36, 192)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 36, 192)      37056       input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 36, 192)      37056       input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_29 (Reshape)            (None, 36, 8, 24)    0           dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_30 (Reshape)            (None, 36, 8, 24)    0           dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           (None, 36, 192)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 36, 8, 8)     0           reshape_29[0][0]                 \n",
      "                                                                 reshape_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 36, 192)      37056       input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 36, 8, 8)     0           lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_28 (Reshape)            (None, 36, 8, 24)    0           dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 36, 8, 24)    0           lambda_17[0][0]                  \n",
      "                                                                 reshape_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_31 (Reshape)            (None, 36, 192)      0           lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 36, 192)      0           reshape_31[0][0]                 \n",
      "                                                                 input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 36, 32)       6176        add_4[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 117,344\n",
      "Trainable params: 117,344\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 28, 28, 32)   160         input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 14, 14, 32)   0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 13, 13, 64)   8256        max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 7, 7, 64)     0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 6, 6, 192)    49344       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_27 (Reshape)            (None, 36, 192)      0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "model_11 (Model)                (None, 36, 32)       117344      reshape_27[0][0]                 \n",
      "                                                                 reshape_27[0][0]                 \n",
      "                                                                 reshape_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_32 (Reshape)            (None, 6, 6, 32)     0           model_11[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_l_4 (NormL)                (None, 6, 6, 32)     64          reshape_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 1152)         0           norm_l_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 256)          295168      flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 10)           2570        dense_29[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 472,906\n",
      "Trainable params: 472,906\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.3538 - acc: 0.8912 - val_loss: 0.0615 - val_acc: 0.9805\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0565 - acc: 0.9826 - val_loss: 0.0454 - val_acc: 0.9852\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout,  Conv2D, Input, Lambda, Flatten, TimeDistributed\n",
    "from keras.layers import Add, Reshape, MaxPooling2D, Concatenate, Embedding, RepeatVector\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.engine.topology import Layer\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "def MultiHeadsAttModel(l=8*8, d=512, dv=64, dout=512, nv = 8 ): #l=6*6, d=64*3 , dv=8*3, dout=32, nv = 8\n",
    "    v1 = Input(shape = (l, d))\n",
    "    q1 = Input(shape = (l, d))\n",
    "    k1 = Input(shape = (l, d))\n",
    "\n",
    "    v2 = Dense(dv*nv, activation = \"relu\")(v1) # we want every encoding to 64*3 as the initial encoding so dv*nv 8*3*8 W_V\n",
    "    q2 = Dense(dv*nv, activation = \"relu\")(q1) #same W_Q\n",
    "    k2 = Dense(dv*nv, activation = \"relu\")(k1) #same W_K\n",
    "\n",
    "    v = Reshape([l, nv, dv])(v2) # for all the nv attention heads find those components\n",
    "    q = Reshape([l, nv, dv])(q2) \n",
    "    k = Reshape([l, nv, dv])(k2) \n",
    "\n",
    "    att = Lambda(lambda x: K.batch_dot(x[0],x[1] ,axes=[3,3]) / np.sqrt(dv),\n",
    "                 output_shape=(l, nv, nv))([q,k])# l, nv, nv\n",
    "    att = Lambda(lambda x:  K.softmax(x) , output_shape=(l, nv, nv))(att)\n",
    "\n",
    "    out = Lambda(lambda x: K.batch_dot(x[0], x[1],axes=[3,4]),  output_shape=(l, nv, dv))([att, v])\n",
    "    out = Reshape([l, d])(out)\n",
    "    \n",
    "    out = Add()([out, q1])\n",
    "\n",
    "    out = Dense(dout, activation = \"relu\")(out)\n",
    "    m = Model(inputs=[q1,k1,v1], outputs=out)\n",
    "    print(m.summary())\n",
    "    return  Model(inputs=[q1,k1,v1], outputs=out)\n",
    "\n",
    "class NormL(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(NormL, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.a = self.add_weight(name='kernel', \n",
    "                                      shape=(1,input_shape[-1]),\n",
    "                                      initializer='ones',\n",
    "                                      trainable=True)\n",
    "        self.b = self.add_weight(name='kernel', \n",
    "                                      shape=(1,input_shape[-1]),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        super(NormL, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, x):\n",
    "        eps = 0.000001\n",
    "        mu = K.mean(x, keepdims=True, axis=-1)\n",
    "        sigma = K.std(x, keepdims=True, axis=-1)\n",
    "        ln_out = (x - mu) / (sigma + eps)\n",
    "        return ln_out*self.a + self.b\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "    \n",
    "if __name__ == '__main__':   \n",
    "\n",
    "    nb_classes = 10\n",
    "\n",
    "    # the data, shuffled and split between tran and test sets\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    print(\"X_train original shape\", X_train.shape)\n",
    "    print(\"y_train original shape\", y_train.shape)\n",
    "\n",
    "    X_train = X_train.reshape(60000, 28,28,1)\n",
    "    X_test = X_test.reshape(10000, 28,28,1)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "    print(\"Training matrix shape\", X_train.shape)\n",
    "    print(\"Testing matrix shape\", X_test.shape)\n",
    "\n",
    "    Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "    Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "    \n",
    "    inp = Input(shape = (28,28,1))\n",
    "    x = Conv2D(32,(2,2),activation='relu', padding='same')(inp)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(64,(2,2),activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "    x = Conv2D(64*3,(2,2),activation='relu')(x)\n",
    "    \n",
    "    if True:\n",
    "        x = Reshape([6*6,64*3])(x) #number of words(6*6) * it's encoding(64*3) output by the encoder     \n",
    "        att = MultiHeadsAttModel(l=6*6, d=64*3 , dv=8*3, dout=32, nv = 8 )\n",
    "        x = att([x,x,x])#sent to the decoder to use attention heads to decode \n",
    "        x = Reshape([6,6,32])(x)\n",
    "        x = NormL()(x)\n",
    "    \n",
    "    x = Flatten()(x) \n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    print(model.summary())\n",
    "    from keras.utils import plot_model\n",
    "    plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    from IPython.display import Image\n",
    "    Image(filename='model.png')\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    #tbCallBack = TensorBoard(log_dir='./Graph/mhatt1', histogram_freq=0, write_graph=True, write_images=True)\n",
    "    #train_datagen = ImageDataGenerator(preprocessing_function=augment_img)\n",
    "    #train_datagen.fit(x_train)\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=500, \n",
    "              epochs=2,\n",
    "              verbose=1,          \n",
    "              validation_data=(X_test, Y_test)\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34631,
     "status": "ok",
     "timestamp": 1566885515023,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD2lkgdC-M_53HbDklxXbBN0K9q5UMGVQMUi_3gQQ=s64",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "UptBpAFKQWff",
    "outputId": "337969c4-e2e4-40e3-d453-ced793cb8dc6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72045\n",
      "72045\n",
      "(72045, 64, 64, 3)\n",
      "(72045, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0827 05:58:26.215000 139979077339008 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0827 05:58:26.248397 139979077339008 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0827 05:58:26.256499 139979077339008 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0827 05:58:26.312398 139979077339008 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0827 05:58:26.313385 139979077339008 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0827 05:58:29.852357 139979077339008 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0827 05:58:31.011237 139979077339008 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 16)   1216        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 16)   1216        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 16)   1216        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 16)   0           batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 16)   6416        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 16)   6416        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 16)   6416        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 16)   64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 16)   64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 16)   64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 16)   0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 16)   6416        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 16)   6416        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 16)   6416        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 16)   64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 64, 16)   64          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 64, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 64, 16)   0           batch_normalization_7[0][0]      \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 16)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 32)   128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 32)   128         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 32)   0           batch_normalization_10[0][0]     \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 32)   9248        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 32)   9248        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 32)   9248        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 32)   128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 32)   128         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 32)   128         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 32)   0           batch_normalization_13[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 32)   9248        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 32)   9248        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 32)   9248        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 32)   128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 32)   128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 32)   128         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 32, 32)   0           batch_normalization_16[0][0]     \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 32)   0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 64)   256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 64)   256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 64)   256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
      "                                                                 batch_normalization_20[0][0]     \n",
      "                                                                 batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 64)   36928       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 64)   36928       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 64)   36928       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 64)   256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 64)   256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 64)   256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
      "                                                                 batch_normalization_23[0][0]     \n",
      "                                                                 batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 64)   36928       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 64)   36928       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 64)   36928       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 64)   256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 64)   256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 64)   256         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
      "                                                                 batch_normalization_26[0][0]     \n",
      "                                                                 batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 64)     0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 128)    73856       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 8, 128)    73856       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 8, 128)    73856       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 128)    512         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 8, 128)    512         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 128)    512         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 128)    0           batch_normalization_28[0][0]     \n",
      "                                                                 batch_normalization_29[0][0]     \n",
      "                                                                 batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 128)    147584      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 8, 8, 128)    147584      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 8, 128)    147584      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 8, 128)    512         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 8, 128)    512         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 8, 8, 128)    512         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 128)    0           batch_normalization_31[0][0]     \n",
      "                                                                 batch_normalization_32[0][0]     \n",
      "                                                                 batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 8, 128)    147584      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 8, 8, 128)    147584      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 8, 8, 128)    147584      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 8, 8, 128)    512         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 8, 8, 128)    512         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 8, 8, 128)    512         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 128)    0           batch_normalization_34[0][0]     \n",
      "                                                                 batch_normalization_35[0][0]     \n",
      "                                                                 batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 128)    0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 128)          0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           1290        global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 1,505,610\n",
      "Trainable params: 1,501,290\n",
      "Non-trainable params: 4,320\n",
      "__________________________________________________________________________________________________\n",
      "This is the number of trainable weights before freezing the conv base: 146\n"
     ]
    }
   ],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.math import add_n\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, GlobalAveragePooling2D\n",
    "from PIL import Image\n",
    "from keras import losses, optimizers, metrics\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import add, concatenate\n",
    "BASE = \"drive/NumtaDB/\"\n",
    "X_train = np.load(BASE+'x_train_all_64.npy')\n",
    "Y_train = np.load(BASE+'x_label_all_64.npy')\n",
    "#X_train = X_train[:len(X_train)//2]\n",
    "#Y_train = Y_train[:len(Y_train)//2]\n",
    "print(len(X_train))\n",
    "print(len(Y_train))\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.1, random_state=42, shuffle=True)\n",
    "aug1 = iaa.GaussianBlur(sigma=(0, 2.0))\n",
    "aug2 = iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5)\n",
    "aug3 = iaa.Multiply((0.8, 1.2), per_channel=0.2)\n",
    "aug4 = iaa.Affine(\n",
    "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "        rotate=(-45, 45),\n",
    "        shear=(-8, 8))\n",
    "\n",
    "aug5 = iaa.CoarseDropout(p=0.2, size_percent = 0.15)\n",
    "aug6 = iaa.ContrastNormalization((0.75, 1.5))\n",
    "aug7 = iaa.Pepper(p=0.05)\n",
    "\n",
    "def augment_img(img):\n",
    "    \n",
    "    i = np.random.randint(0,9)\n",
    "\n",
    "    if i==0:\n",
    "        img_adapteq = img\n",
    "\n",
    "    elif i==1:\n",
    "        img_adapteq = aug4.augment_image(img)\n",
    "        img_adapteq = aug1.augment_image(img_adapteq)\n",
    "\n",
    "    elif i==2:\n",
    "        img_adapteq = aug2.augment_image(img)\n",
    "\n",
    "    elif i==3:\n",
    "        img_adapteq = aug3.augment_image(img)\n",
    "\n",
    "    elif i==4:\n",
    "        img_adapteq = aug4.augment_image(img)  \n",
    " \n",
    "    elif i==5:\n",
    "        img_adapteq = aug5.augment_image(img)  \n",
    "\n",
    "    elif i==6:\n",
    "        img_adapteq = aug6.augment_image(img)  \n",
    " \n",
    "    elif i==7:\n",
    "        img_adapteq = aug4.augment_image(img)\n",
    "        img_adapteq = aug7.augment_image(img_adapteq)\n",
    "        img_adapteq = aug1.augment_image(img_adapteq)\n",
    "\n",
    "    elif i==8:\n",
    "        img_adapteq = aug4.augment_image(img)\n",
    "        img_adapteq = aug2.augment_image(img_adapteq)\n",
    "    \n",
    "    img_adapteq = img_adapteq.astype('float32')\n",
    "    img_adapteq /= 255.\n",
    "\n",
    "    return img_adapteq\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=augment_img)\n",
    "train_datagen.fit(x_train)\n",
    "l2_lambda = 0.0001\n",
    "def make_block(inp, k, depth):\n",
    "    x1 = Conv2D(depth, (k, k), padding='same',activation='relu',kernel_regularizer=l2(l2_lambda), dilation_rate = 1)(inp)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x2 = Conv2D(depth, (k, k), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda), dilation_rate = 2)(inp)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x3 = Conv2D(depth, (k, k), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda), dilation_rate = 4)(inp)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    return add([x1, x2, x3])\n",
    "\n",
    "def dCNN():\n",
    "    inp = Input(shape=(64, 64, 3))  \n",
    "    x = make_block(inp, 5, 16)\n",
    "    x = make_block(x, 5, 16)\n",
    "    x = make_block(x, 5, 16)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x) \n",
    "    \n",
    "    x = make_block(x, 3, 32)\n",
    "    x = make_block(x, 3, 32)\n",
    "    x = make_block(x, 3, 32)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x) \n",
    "    \n",
    "    x = make_block(x, 3, 64)\n",
    "    x = make_block(x, 3, 64)\n",
    "    x = make_block(x, 3, 64)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x) \n",
    "\n",
    "    x = make_block(x, 3, 128)\n",
    "    x = make_block(x, 3, 128)\n",
    "    x = make_block(x, 3, 128)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x) \n",
    "    \n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(10, activation = 'softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=x) # To define a model, just specify its input and output layers\n",
    "    return model\n",
    "\n",
    "def all_cnn():\n",
    "        \n",
    "    inp = Input(shape=(height, width, depth)) \n",
    "    \n",
    "    x = Conv2D(16, (5, 5), padding='same',activation='relu',kernel_regularizer=l2(l2_lambda))(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(16, (5, 5), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(16, (5, 5), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), padding='same',activation='relu',kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(32, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(32, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), padding='same',activation='relu',kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same',activation='relu',kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(10, activation = 'softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=x) # To define a model, just specify its input and output layers\n",
    "    return model\n",
    "  \n",
    "#model =all_cnn()\n",
    "model = dCNN()\n",
    "model.summary()\n",
    "print('This is the number of trainable weights before freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 907417,
     "status": "error",
     "timestamp": 1566887846908,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD2lkgdC-M_53HbDklxXbBN0K9q5UMGVQMUi_3gQQ=s64",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "DmIQonO-XMYC",
    "outputId": "637d561e-5cea-4fe6-c005-adaa6fc4dc4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "129/129 [==============================] - 299s 2s/step - loss: 0.2366 - acc: 0.9714 - val_loss: 0.1829 - val_acc: 0.9872\n",
      "Epoch 2/10\n",
      "129/129 [==============================] - 287s 2s/step - loss: 0.2128 - acc: 0.9741 - val_loss: 0.1881 - val_acc: 0.9802\n",
      "Epoch 3/10\n",
      "129/129 [==============================] - 287s 2s/step - loss: 0.1971 - acc: 0.9761 - val_loss: 0.1647 - val_acc: 0.9874\n",
      "Epoch 4/10\n",
      " 11/129 [=>............................] - ETA: 4:05 - loss: 0.1868 - acc: 0.9785"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-088a687f6ebe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mBS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mBS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                    )\n\u001b[1;32m     11\u001b[0m '''\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BS = 500\n",
    "#from keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy', \n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "model.fit_generator(train_datagen.flow(x_train, y_train , batch_size = BS),\n",
    "              epochs=10, verbose=1, validation_data = (x_test.astype('float32')/255., y_test),\n",
    "                    steps_per_epoch=int(len(x_train))//BS,\n",
    "                    validation_steps=int(len(x_test))/BS\n",
    "                   )\n",
    "'''\n",
    "model.fit_generator( train_datagen.flow(x_train, y_train),\n",
    "              epochs=2, verbose=1, validation_data = (x_test, y_test),\n",
    "                    batch_size=BS\n",
    "                   )\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1837200,
     "status": "error",
     "timestamp": 1566884258930,
     "user": {
      "displayName": "Mahim Anzum Haque pantho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD2lkgdC-M_53HbDklxXbBN0K9q5UMGVQMUi_3gQQ=s64",
      "userId": "07659887497514272211"
     },
     "user_tz": -360
    },
    "id": "UeMK9eUJY0eK",
    "outputId": "8198d147-9a99-45dc-a656-40a438ec1b9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6711/57636 [==>...........................] - ETA: 3:48:54 - loss: 0.1690 - acc: 0.9662"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-0e655b6619b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0mkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;31m##end training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-0e655b6619b5>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, batch_size, epochs, x, y, n_fold, kf, model_name)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         model.fit_generator(train_datagen.flow(x_train, y_train, batch_size= batch_size),steps_per_epoch = len(x_train),\n\u001b[0;32m--> 246\u001b[0;31m                       epochs=epochs, verbose=1, validation_data = (x_valid, y_valid), callbacks = callbacks)\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m#model.load_weights(filepath= model_name + '_heavy_aug_fold_64' + str(i) + '.hdf5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "#from ddrop.layers import DropConnect\n",
    "from imgaug import augmenters as iaa\n",
    "#from densenet import densenet121_model\n",
    "from keras.applications.densenet import DenseNet121\n",
    "#load data\n",
    "X_train_all = np.load(BASE+'x_train_all_64.npy')\n",
    "y_train_all = np.load(BASE+'x_label_all_64.npy')\n",
    "\n",
    "#define augmnetation\n",
    "aug1 = iaa.GaussianBlur(sigma=(0, 2.0))\n",
    "aug2 = iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5)\n",
    "aug3 = iaa.Multiply((0.8, 1.2), per_channel=0.2)\n",
    "aug4 = iaa.Affine(\n",
    "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "        rotate=(-45, 45),\n",
    "        shear=(-8, 8))\n",
    "\n",
    "aug5 = iaa.CoarseDropout(p=0.2, size_percent = 0.15)\n",
    "aug6 = iaa.ContrastNormalization((0.75, 1.5))\n",
    "aug7 = iaa.Pepper(p=0.05)\n",
    "\n",
    "def augment_img(img):\n",
    "    \n",
    "    i = np.random.randint(0,9)\n",
    "\n",
    "    if i==0:\n",
    "        img_adapteq = img\n",
    "\n",
    "    elif i==1:\n",
    "        img_adapteq = aug4.augment_image(img)\n",
    "        img_adapteq = aug1.augment_image(img_adapteq)\n",
    "\n",
    "    elif i==2:\n",
    "        img_adapteq = aug2.augment_image(img)\n",
    "\n",
    "    elif i==3:\n",
    "        img_adapteq = aug3.augment_image(img)\n",
    "\n",
    "    elif i==4:\n",
    "        img_adapteq = aug4.augment_image(img)  \n",
    " \n",
    "    elif i==5:\n",
    "        img_adapteq = aug5.augment_image(img)  \n",
    "\n",
    "    elif i==6:\n",
    "        img_adapteq = aug6.augment_image(img)  \n",
    " \n",
    "    elif i==7:\n",
    "        img_adapteq = aug4.augment_image(img)\n",
    "        img_adapteq = aug7.augment_image(img_adapteq)\n",
    "        img_adapteq = aug1.augment_image(img_adapteq)\n",
    "\n",
    "    elif i==8:\n",
    "        img_adapteq = aug4.augment_image(img)\n",
    "        img_adapteq = aug2.augment_image(img_adapteq)\n",
    "    \n",
    "    img_adapteq = img_adapteq.astype('float32')\n",
    "    img_adapteq /= 255.\n",
    "\n",
    "    return img_adapteq\n",
    "\n",
    "class LearningRateDecay(Callback):\n",
    "    '''Learning rate scheduler.\n",
    "    # Arguments\n",
    "        schedule: a function that takes an epoch index as input\n",
    "            (integer, indexed from 0) and returns a new\n",
    "            learning rate as output (float).\n",
    "    '''\n",
    "    def __init__(self, decay, every_n=1, verbose=0):\n",
    "        Callback.__init__(self)\n",
    "        self.decay = decay\n",
    "        self.every_n = every_n\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if not (epoch and epoch % self.every_n == 0):\n",
    "            return\n",
    "\n",
    "        assert hasattr(self.model.optimizer, 'lr'), \\\n",
    "            'Optimizer must have a \"lr\" attribute.'\n",
    "        current_lr = K.get_value(self.model.optimizer.lr)\n",
    "        new_lr = current_lr * self.decay\n",
    "        if self.verbose > 0:\n",
    "            print(' \\nEpoch %05d: reducing learning rate' % (epoch))\n",
    "            sys.stderr.write('new lr: %.5f\\n' % new_lr)\n",
    "        K.set_value(self.model.optimizer.lr, new_lr)\n",
    "        \n",
    "def make_block(inp, k, depth):\n",
    "    \n",
    "    x1 = Conv2D(depth, (k, k), padding='same',activation='relu',kernel_regularizer=l2(l2_lambda), dilation_rate = 1)(inp)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x2 = Conv2D(depth, (k, k), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda), dilation_rate = 2)(inp)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x3 = Conv2D(depth, (k, k), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda), dilation_rate = 4)(inp)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    return add([x1, x2, x3])\n",
    "\n",
    "\n",
    "\n",
    "def cnn_with_multi_scale_high_level_feature_aggregation():\n",
    "    \n",
    "    inp = Input(shape=(height, width, depth))  \n",
    "\n",
    "    x = Conv2D(16, (5, 5), padding='same',activation='relu',kernel_regularizer=l2(l2_lambda))(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(16, (5, 5), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(16, (5, 5), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(32, (3, 3), padding='same',activation='relu',kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(32, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(32, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x) \n",
    "\n",
    "    x = make_block(x, 3, 64)\n",
    "    x = make_block(x, 3, 64)\n",
    "    x = make_block(x, 3, 64)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x) \n",
    "       \n",
    "    x = Flatten()(x)\n",
    "    #x = DropConnect(Dense(128, activation='relu'), prob=0.2)(x)\n",
    "    x = Dense(10, activation = 'softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=x) \n",
    "    return model\n",
    "\n",
    "def multi_scale_all_level_feature_aggregation_cnn_model():\n",
    "    \n",
    "    inp = Input(shape=(64, 64, 3))  \n",
    " \n",
    "    x = make_block(inp, 5, 16)\n",
    "    x = make_block(x, 5, 16)\n",
    "    x = make_block(x, 5, 16)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x) \n",
    "\n",
    "    x = make_block(x, 3, 32)\n",
    "    x = make_block(x, 3, 32)\n",
    "    x = make_block(x, 3, 32)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x) \n",
    "    \n",
    "\n",
    "    x = make_block(x, 3, 64)\n",
    "    x = make_block(x, 3, 64)\n",
    "    x = make_block(x, 3, 64)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x) \n",
    "\n",
    "    x = make_block(x, 3, 128)\n",
    "    x = make_block(x, 3, 128)\n",
    "    x = make_block(x, 3, 128)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x) \n",
    "    \n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(10, activation = 'softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=x) # To define a model, just specify its input and output layers\n",
    "    return model\n",
    "\n",
    "\n",
    "def all_cnn():\n",
    "        \n",
    "    inp = Input(shape=(height, width, depth)) \n",
    "    \n",
    "    x = Conv2D(16, (5, 5), padding='same',activation='relu',kernel_regularizer=l2(l2_lambda))(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(16, (5, 5), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(16, (5, 5), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), padding='same',activation='relu',kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(32, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(32, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), padding='same',activation='relu',kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same',activation='relu',kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same',activation='relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(10, activation = 'softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=x) # To define a model, just specify its input and output layers\n",
    "    return model\n",
    "\n",
    "height, width, depth = 64, 64, 3 \n",
    "num_classes = 10 \n",
    "l2_lambda = 0.0001 # use 0.0001 as a L2-regularisation factor\n",
    "def Densenet121():\n",
    "    \n",
    "    base_model = Densenet121(img_rows=64, img_cols=64, color_type=3, num_classes=10, dropout_rate = 0.2)\n",
    "    return base_model\n",
    "\n",
    "\n",
    "def train_model(model, batch_size, epochs, x, y, n_fold, kf, model_name):\n",
    "\n",
    "    i = 1\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        \n",
    "        x_train = x[train_index]; x_valid = x[test_index]\n",
    "        y_train = y[train_index]; y_valid = y[test_index]\n",
    "\n",
    "        x_valid = x_valid.astype('float32')/255.\n",
    "        train_datagen = ImageDataGenerator(preprocessing_function=augment_img)\n",
    "##\n",
    "        train_datagen.fit(x_train)\n",
    "\n",
    "        callbacks = [EarlyStopping(monitor='val_acc', patience=8, verbose=1, min_delta=1e-6),\n",
    "             LearningRateDecay(0.5, every_n = 8, verbose=1),\n",
    "             ModelCheckpoint(filepath= model_name + '_heavy_aug_fold_64' + str(i) + '.hdf5', verbose=1,monitor = 'val_acc',\n",
    "                             save_best_only=True, save_weights_only=True, mode='auto')]\n",
    "        \n",
    "        model = model\n",
    "\n",
    "        model.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy', \n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "        model.fit_generator(train_datagen.flow(x_train, y_train, batch_size= batch_size),steps_per_epoch = len(x_train),\n",
    "                      epochs=epochs, verbose=1, validation_data = (x_valid, y_valid), callbacks = callbacks)\n",
    "\n",
    "        #model.load_weights(filepath= model_name + '_heavy_aug_fold_64' + str(i) + '.hdf5')\n",
    "\n",
    "\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        if i <= n_fold:\n",
    "            print('Now beginning training for {} fold {}\\n\\n'.format(model_name,i))\n",
    "        else:\n",
    "            print('Finished training {}\\n\\n!'.format(model_name))\n",
    "\n",
    "models = [all_cnn(), multi_scale_all_level_feature_aggregation_cnn_model(), cnn_with_multi_scale_high_level_feature_aggregation(), Densenet121]\n",
    "model_name = ['all_cnn', 'multi_scale_all_level_feature_aggregation_cnn_model','cnn_with_multi_scale_high_level_feature_aggregation','Densenet121']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "from sklearn.model_selection import KFold\n",
    "batch_size = 256\n",
    "epochs = 30\n",
    "n_fold = 5\n",
    "\n",
    "##train start\n",
    "\n",
    "for j in range(len(models)): \n",
    "    model = models[j]\n",
    "    kf = KFold(n_splits=n_fold, shuffle=True)\n",
    "    train_model(model, batch_size, epochs, X_train_all,y_train_all, n_fold, kf, model_name[j])\n",
    "#    \n",
    "##end training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9uR_h1mVbBJ4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Numtadb.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
